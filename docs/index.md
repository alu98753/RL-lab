# NYCU 114-1 å¼·åŒ–å­¸ç¿’å°ˆè«–
---
> æœ¬å°ˆæ¡ˆç‚º **ã€Œå¼·åŒ–å­¸ç¿’å°ˆè«–ã€(Selected Topics in Reinforcement Learning)** èª²ç¨‹çš„å¯¦ä½œèˆ‡å°ˆæ¡ˆæˆæœï¼Œæ¶µè“‹å¾åŸºç¤ RL æ¦‚å¿µåˆ° DQNã€PPOã€TD3 åŠæœ€çµ‚å°ˆæ¡ˆå¯¦ä½œï¼Œå®Œæ•´å±•ç¤ºå¼·åŒ–å­¸ç¿’çš„æ‡‰ç”¨èˆ‡èƒ½åŠ›ã€‚

![æœŸæœ«è³½è»Šå°ˆæ¡ˆç¸®åœ–](racecar_gym.png)

---

## ğŸ† **èª²ç¨‹è³‡è¨Š**
- **èª²ç¨‹åç¨±**ï¼šå¼·åŒ–å­¸ç¿’å°ˆè«–ï¼ˆSelected Topics in Reinforcement Learningï¼‰  
- **æˆèª²å–®ä½**ï¼šè³‡ç§‘å·¥ç¢© | èª²è™Ÿï¼š535518 | å­¸åˆ†æ•¸ï¼š3.0  
- **æˆèª²æ•™å¸«**ï¼šå³æ¯…æˆ  
- **å…ˆä¿®å»ºè­°**ï¼šMachine Learning / Deep Learning  
- **èª²ç¨‹ç›®æ¨™**ï¼š
  1. æŒæ¡å¼·åŒ–å­¸ç¿’ (RL) çš„æ ¸å¿ƒæ¦‚å¿µ
  2. äº†è§£æœ€æ–° RL æŠ€è¡“åŠå…¶æ‡‰ç”¨
  3. ç†Ÿæ‚‰ RL é–‹ç™¼å·¥å…·ï¼Œå¦‚ PyTorchã€Gazebo ç­‰
  4. é€éå°ˆæ¡ˆå¯¦ä½œæ‡‰ç”¨ RLï¼ˆå¦‚ DeepRacerã€è‡ªä¸»é§•é§›ç­‰ï¼‰

---

## ğŸ”¥ **å¯¦ä½œå…§å®¹**

| ğŸ“‚ å°ˆæ¡ˆåç¨± | ğŸ¯ å…§å®¹ | ğŸš€ æ–¹æ³• | ğŸ“Œ é—œéµæŠ€è¡“ |
|------------|---------|--------|------------|
| **Lab1-2048** | 2048 éŠæˆ²çš„ RL è§£æ³• | Q-Learning | MDPã€ç‹€æ…‹å€¼ä¼°è¨ˆ |
| **Lab2-DQN** | ä½¿ç”¨ DQN é€²è¡ŒéŠæˆ²è¨“ç·´ | Deep Q-Network | Q-Learningã€Experience Replay |
| **Lab3-PPO** | Proximal Policy Optimization | Policy Gradient | Actor-Criticã€Advantage Estimation |
| **Lab4-TD3** | Twin Delayed Deep Deterministic Policy Gradient | Continuous Control | DDPGã€Delayed Policy Update |
| **Final-LAB** | æœŸæœ«å°ˆæ¡ˆ-racecar_gym | è‡ªè¡Œæ‡‰ç”¨æ‰€å­¸ | RL-based Optimization |

ğŸ›  **æŠ€è¡“æ£§**ï¼š
- **ç¨‹å¼èªè¨€**ï¼šPython
- **æ¡†æ¶**ï¼šPyTorch
- **æ¼”ç®—æ³•**ï¼šDQN, PPO, TD3, Policy Gradient
- **ç’°å¢ƒ**ï¼šGym, Stable-Baselines3
- **é–‹ç™¼å·¥å…·**ï¼šJupyter Notebook, Docker , Git , vscode

---

## ğŸ… **å°ˆæ¡ˆç‰¹è‰²**
âœ… **æ¶µè“‹ Value-Based & Policy-Based æ–¹æ³•**ï¼šå¾ DQN åˆ° PPOï¼ŒæŒæ¡å¼·åŒ–å­¸ç¿’ä¸»è¦ç­–ç•¥  
âœ… **å¼·èª¿å¯¦ä½œèˆ‡æ‡‰ç”¨**ï¼šä¸åƒ…ç†è§£ç†è«–ï¼Œé‚„å°‡ RL æ‡‰ç”¨æ–¼ä¸åŒè¨“ç·´å ´æ™¯  
âœ… **è™•ç†é€£çºŒå‹•ä½œç©ºé–“**ï¼šé€é DDPGã€TD3 ä¾†è§£æ±ºé€£çºŒæ§åˆ¶å•é¡Œ  

---

## ğŸ“– **èª²ç¨‹å¤§ç¶±**
1ï¸âƒ£ **æ ¸å¿ƒæ¦‚å¿µ**ï¼šé¦¬å¯å¤«æ±ºç­–éç¨‹ (MDP)ã€å‹•æ…‹è¦åŠƒã€Q-Learning  
2ï¸âƒ£ **å¼·åŒ–å­¸ç¿’æ¼”ç®—æ³•**ï¼šDQN, DDQN, Dueling DQN, Policy Gradient, PPO, TD3  
3ï¸âƒ£ **æ‡‰ç”¨é ˜åŸŸ**ï¼šDeepRacerã€Rubikâ€™s Cube è§£æ³•ã€å„ªåŒ– (JSP/TSP)  
4ï¸âƒ£ **é€²éšæ¢ç´¢æŠ€è¡“**ï¼šAlphaGoã€MuZeroã€å¤šä»£ç† RL (MARL)  
5ï¸âƒ£ **å¼·åŒ–å­¸ç¿’è¦åŠƒ**ï¼šMCTS, Path Consistency, Abstraction  

ğŸ“Œ **å®Œæ•´èª²ç¨‹å¤§ç¶±è«‹è¦‹ï¼š[èª²ç¨‹é€²åº¦è¡¨](https://timetable.nycu.edu.tw/?r=main/crsoutline&Acy=113&Sem=1&CrsNo=535518&lang=zh-tw)**

---

## ğŸ“ˆ **å­¸ç¿’æˆæœ**

**Final-LABæ’å: 5/84** 

---

## ğŸ¤ **è¯çµ¡æ–¹å¼**
å¦‚æœä½ å°æˆ‘çš„ RL å¯¦ä½œæœ‰èˆˆè¶£ï¼Œæˆ–æœ‰ä»»ä½•å•é¡Œï¼Œæ­¡è¿è¯ç¹«ï¼š

ğŸ“§ **Email**: clu98753.cs13@nycu.edu.tw 

ğŸ“Œ **GitHub**: [alu98753](https://github.com/alu98753)  

---
æ–½å·¥ä¸­:

ğŸ“Œ **æ›´å¤šè¨“ç·´çµæœè«‹è¦‹ [`results/`](./results/)**
